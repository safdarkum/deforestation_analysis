{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed7ae84-34df-4ef3-8b6d-4a6972bc9976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required packages and libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Loading the clean data as CSV \n",
    "df = pd.read_csv(\"E:\\IA\\Machine Learning_Manuscript\\Refine data\\Test Folder\\Test_2.csv\")  \n",
    "\n",
    "# Independent variables/major drivers of deforestation\n",
    "X = df[['Population Growth', 'Livelihood activities','Forest Fire',\t'Fuelwood Collection', 'Inadequate Education', 'Poor Forest Management',\n",
    "        'Illegal Logging',\t'Distance from Forest'\n",
    "]]\n",
    "\n",
    "# Dependent variable\n",
    "y = df['Deforestation']\n",
    "\n",
    "# Adding constant\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fitting logistic regression model model\n",
    "logit_model = sm.Logit(y, X)\n",
    "result = logit_model.fit()\n",
    "\n",
    "print(result.summary())\n",
    "df['Deforestation'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff57244-085d-455e-a52c-f8b3fbcda8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing Odds Ratios (Exp(B)) as it is missing in previous model:\n",
    "# X = independent variables (with constant), y = dependent binary variable\n",
    "logit_model = sm.Logit(y, X)\n",
    "result = logit_model.fit()\n",
    "\n",
    "# Get coefficients\n",
    "params = result.params\n",
    "\n",
    "# Computing exp(B)\n",
    "odds_ratios = np.exp(params)\n",
    "\n",
    "print(\"Odds Ratios (Exp(B)):\\n\")\n",
    "print(odds_ratios)\n",
    "\n",
    "# Getting confidence intervals\n",
    "conf = result.conf_int()\n",
    "conf['OR'] = odds_ratios\n",
    "conf.columns = ['2.5%', '97.5%', 'OR']\n",
    "\n",
    "# Adding p-values\n",
    "conf['p-value'] = result.pvalues\n",
    "\n",
    "# Adding B (coefficients) =\n",
    "conf['B'] = result.params\n",
    "\n",
    "print(conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ef7e85-b477-4b29-810e-e5f552c6ec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the results of both models in the table\n",
    "logit_model = sm.Logit(y, X)\n",
    "result = logit_model.fit()\n",
    "\n",
    "# Coefficients and stats\n",
    "params = result.params\n",
    "conf = result.conf_int()\n",
    "conf.columns = ['2.5%', '97.5%']\n",
    "odds_ratios = np.exp(params)\n",
    "\n",
    "# Combine everything\n",
    "summary_table = pd.DataFrame({\n",
    "    'B': params,\n",
    "    'SE': result.bse,\n",
    "    'z-value': result.tvalues,\n",
    "    'p-value': result.pvalues,\n",
    "    '95% CI Lower': conf['2.5%'],\n",
    "    '95% CI Upper': conf['97.5%'],\n",
    "    'Exp(B)': odds_ratios\n",
    "})\n",
    "\n",
    "summary_table = summary_table.round(3)\n",
    "\n",
    "# Exportting to Excel and display\n",
    "summary_table.to_excel('logit_summary.xlsx')\n",
    "summary_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f11286-b1e1-4aa7-b7d7-aab88a7060a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the Variance Inflation Factor (VF)\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "X = df.drop(columns='Deforestation')  # independent variables\n",
    "X = add_constant(X)\n",
    "vif = pd.DataFrame()\n",
    "vif[\"Variable\"] = X.columns\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "print(vif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fed038-f6f5-413e-9825-b9596fb44973",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance Matrices for Machine Learning Models\n",
    "\n",
    "# 1. Importing the required Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score,\n",
    "    roc_curve, auc\n",
    ")\n",
    "\n",
    "# 2. Spliting the Data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Standardize for SVM & Logistic\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 4. Defining Machine Learning Models \n",
    "log_model = LogisticRegression()\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "svm_model = SVC(probability=True, kernel='linear', random_state=42)\n",
    "\n",
    "#5. Training Models \n",
    "log_model.fit(X_train_scaled, y_train)\n",
    "rf_model.fit(X_train, y_train)\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 6. Predicting Probabilities \n",
    "y_log_proba = log_model.predict_proba(X_test_scaled)[:, 1]\n",
    "y_rf_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "y_svm_proba = svm_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# 7. Predicting Classes ===\n",
    "y_log_pred = log_model.predict(X_test_scaled)\n",
    "y_rf_pred = rf_model.predict(X_test)\n",
    "y_svm_pred = svm_model.predict(X_test_scaled)\n",
    "\n",
    "# === 8. Evaluating Machine Learning Models ===\n",
    "models = {\n",
    "    'Logistic Regression': (y_test, y_log_pred, y_log_proba),\n",
    "    'Random Forest': (y_test, y_rf_pred, y_rf_proba),\n",
    "    'SVM': (y_test, y_svm_pred, y_svm_proba)\n",
    "}\n",
    "\n",
    "for name, (yt, yp, yp_prob) in models.items():\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(\"Accuracy:\", accuracy_score(yt, yp))\n",
    "    print(\"Classification Report:\\n\", classification_report(yt, yp))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e584a89a-6aee-4a5f-8d4a-d97dea87805b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting ROC Curves for AUC values for all three Machine Learning Models  \n",
    "# Logestic Regression\n",
    "# Random Forest\n",
    "# Supoort Vector Machine\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, log_probs)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, rf_probs)\n",
    "fpr_svm, tpr_svm, _ = roc_curve(y_test, svm_probs)\n",
    "\n",
    "# AUC scores\n",
    "auc_lr = auc(fpr_lr, tpr_lr)\n",
    "auc_rf = auc(fpr_rf, tpr_rf)\n",
    "auc_svm = auc(fpr_svm, tpr_svm)\n",
    "\n",
    "# Plotting the ROC Curves\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr_lr, tpr_lr, label=f'Logistic (AUC = {auc_lr:.2f})')\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {auc_rf:.2f})')\n",
    "plt.plot(fpr_svm, tpr_svm, label=f'SVM (AUC = {auc_svm:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves (All Models)')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.savefig(\"roc_combined_models.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bc4f60-1eb3-4d29-8439-1ea829160a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrices for all three Machine Learning Models \n",
    "# Update below according to actual column names in the CSV file\n",
    "feature_cols = ['Population Growth', 'Livelihood activities', 'Forest Fire', 'Fuelwood Collection', \n",
    "                'Inadequate Education', 'Poor Forest Management', 'Illegal Logging', 'Distance from Forest']\n",
    "target_col = 'Deforestation'\n",
    "\n",
    "# 1. Preparing the data\n",
    "X = df[feature_cols]\n",
    "y = df[target_col]\n",
    "\n",
    "# 2. Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Initializing the ML models\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "svm_model = SVC(probability=True, random_state=42)\n",
    "\n",
    "# 4. Training ML models\n",
    "log_reg.fit(X_train, y_train)\n",
    "rf_model.fit(X_train, y_train)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# 5. Predictting the ML Models \n",
    "log_pred = log_reg.predict(X_test)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "svm_pred = svm_model.predict(X_test)\n",
    "\n",
    "# 6. Creating confusion matrices\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "for ax, model_name, y_pred in zip(\n",
    "    axes,\n",
    "    ['Logistic Regression', 'Random Forest', 'SVM'],\n",
    "    [log_pred, rf_pred, svm_pred]\n",
    "):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(ax=ax, values_format='d')\n",
    "    ax.set_title(f'{model_name}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"combined_confusion_matrices.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ac236a-3125-4053-b69d-9918db8b3f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the color patterns for already fitted models a\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "# Logistic Regression\n",
    "ConfusionMatrixDisplay.from_estimator(log_reg, X_test, y_test, ax=axes[0], cmap='Blues')\n",
    "axes[0].set_title('Logistic Regression')\n",
    "\n",
    "# Random Forest\n",
    "ConfusionMatrixDisplay.from_estimator(rf_model, X_test, y_test, ax=axes[1], cmap='Greens')\n",
    "axes[1].set_title('Random Forest')\n",
    "\n",
    "# SVM\n",
    "ConfusionMatrixDisplay.from_estimator(svm_model, X_test, y_test, ax=axes[2], cmap='Oranges')\n",
    "axes[2].set_title('Support Vector Machine')\n",
    "\n",
    "plt.tight_layout()  # To reduces spacing between subplots\n",
    "plt.savefig(\"Combined_Confusion_Matrix.png\", dpi=500)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cbe835-582f-4563-a8ae-16eaad063ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Validation of AUC scores to check over fitting the models \n",
    "\n",
    "# Defining the ML models\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Defining scoring metric\n",
    "auc_scorer = make_scorer(roc_auc_score, needs_proba=True)\n",
    "\n",
    "# Cross-validated AUC\n",
    "lr_auc_scores = cross_val_score(lr, X, y, cv=5, scoring=auc_scorer)\n",
    "rf_auc_scores = cross_val_score(rf, X, y, cv=5, scoring=auc_scorer)\n",
    "\n",
    "print(\"Logistic Regression AUC Scores:\", lr_auc_scores)\n",
    "print(\"Mean AUC (LR):\", np.mean(lr_auc_scores))\n",
    "print(\"\\nRandom Forest AUC Scores:\", rf_auc_scores)\n",
    "print(\"Mean AUC (RF):\", np.mean(rf_auc_scores))\n",
    "\n",
    "svc = SVC(kernel='linear', probability=True)\n",
    "scores = cross_val_score(svc, X, y, cv=5, scoring='roc_auc')\n",
    "print(f\"SVM AUC scores: {scores}\")\n",
    "print(f\"Mean AUC: {scores.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a10a737-c0c8-43ab-a22c-ca9ec88007f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Cross Validation AUC scores to check over fitting the models \n",
    "# Defining model names and their cross-validated AUC scores\n",
    "models = ['Logistic Regression', 'Random Forest', 'SVM']\n",
    "auc_scores = {\n",
    "    'Logistic Regression': [0.7667, 0.7511, 0.7778, 0.8733, 0.8865],\n",
    "    'Random Forest': [0.9694, 0.9267, 0.9689, 0.9272, 0.9922],\n",
    "    'SVM': [0.7478, 0.7433, 0.7956, 0.8722, 0.8654]\n",
    "}\n",
    "\n",
    "# Calculating mean AUCs\n",
    "mean_aucs = [np.mean(auc_scores[model]) for model in models]\n",
    "\n",
    "# Plotting the AUC scores\n",
    "plt.figure(figsize=(7, 4))\n",
    "for i, model in enumerate(models):\n",
    "    plt.plot(range(1, 6), auc_scores[model], marker='o', label=f'{model} (Mean AUC: {mean_aucs[i]:.3f})')\n",
    "\n",
    "plt.title('Cross-Validated AUC Scores for ML Models')\n",
    "plt.xlabel('Fold Number')\n",
    "plt.ylabel('AUC Score')\n",
    "plt.ylim(0.70, 1.00)\n",
    "plt.xticks(range(1, 6))\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Saving the figure \n",
    "plt.savefig(\"ml_model_auc_comparison.png\", dpi=400)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23227c0e-6124-46b6-8136-9e5f368b8efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Feature Importance Chart for Random Forest and Support Vector Machine \n",
    "\n",
    "#1: Splitting the data ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Removing the 'const' \n",
    "if 'const' in X_train.columns:\n",
    "    X_train = X_train.drop(columns=['const'])\n",
    "    X_test = X_test.drop(columns=['const'])\n",
    "\n",
    "#Training the Models ---\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "svm = SVC(kernel='linear', probability=True, random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Getting Feature Importances \n",
    "# For Random Forest\n",
    "rf_importances = pd.Series(rf.feature_importances_, index=X_train.columns)\n",
    "\n",
    "# For SVM Permutation Importance\n",
    "svm_perm = permutation_importance(svm, X_test, y_test, n_repeats=30, random_state=42)\n",
    "svm_importances = pd.Series(svm_perm.importances_mean, index=X_train.columns)\n",
    "\n",
    "#Creating Combined Table \n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'RF_Importance': rf_importances.values,\n",
    "    'SVM_Importance': svm_importances.values\n",
    "}).sort_values(by='RF_Importance', ascending=False)\n",
    "\n",
    "print(\"\\n=== Combined Feature Importance Table ===\")\n",
    "print(importance_df)\n",
    "\n",
    "\n",
    "# Plotting the Side-by-Side Bar Chart ---\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(10, 4), sharey=True)\n",
    "\n",
    "# Plot for RF\n",
    "axes[0].barh(importance_df['Feature'], importance_df['RF_Importance'], color='green')\n",
    "axes[0].set_title(\"Random Forest Importance\")\n",
    "axes[0].set_xlabel(\"Importance\")\n",
    "\n",
    "# Plot for SVM\n",
    "axes[1].barh(importance_df['Feature'], importance_df['SVM_Importance'], color='purple')\n",
    "axes[1].set_title(\"SVM Permutation Importance\")\n",
    "axes[1].set_xlabel(\"Importance\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Feature_Importance_Comparison_RF_SVM.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65329dbe-0b4f-4788-a054-13e99eded0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install shap scikit-learn matplotlib pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811b62c5-60ab-4478-afd7-0cdca11a791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Predict probabilities Chart for Machine Learning Models \n",
    "# Predict probabilities\n",
    "log_probs = log_reg.predict_proba(X_test)[:, 1]\n",
    "rf_probs = rf_model.predict_proba(X_test)[:, 1]\n",
    "svm_probs = svm_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Sortting by predicted probabilities for cleaner plots\n",
    "sorted_idx = np.argsort(log_probs)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4), sharey=True)\n",
    "\n",
    "# For Logistic Regression\n",
    "axes[0].plot(log_probs[sorted_idx], label='Predicted', color='blue')\n",
    "axes[0].scatter(range(len(y_test)), y_test.values[sorted_idx], label='Actual', color='red', s=10)\n",
    "axes[0].set_title('Logistic Regression')\n",
    "axes[0].set_xlabel('Sorted Observations')\n",
    "axes[0].set_ylabel('Probability')\n",
    "\n",
    "# For Random Forest\n",
    "sorted_idx_rf = np.argsort(rf_probs)\n",
    "axes[1].plot(rf_probs[sorted_idx_rf], color='blue')\n",
    "axes[1].scatter(range(len(y_test)), y_test.values[sorted_idx_rf], color='red', s=10)\n",
    "axes[1].set_title('Random Forest')\n",
    "axes[1].set_xlabel('Sorted Observations')\n",
    "\n",
    "# For SVM\n",
    "sorted_idx_svm = np.argsort(svm_probs)\n",
    "axes[2].plot(svm_probs[sorted_idx_svm], color='blue')\n",
    "axes[2].scatter(range(len(y_test)), y_test.values[sorted_idx_svm], color='red', s=10)\n",
    "axes[2].set_title('SVM')\n",
    "axes[2].set_xlabel('Sorted Observations')\n",
    "\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.savefig(\"predicted_probabilities_all_models.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012209b4-d22d-45e8-8916-c1c34ebbd5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Moderation analysis to check the moderation effect between two indipendent variables on dependent variables\n",
    "df = df.rename(columns={\n",
    "    'Fuelwood Collection': 'Fuelwood_Collection',\n",
    "    'Inadequate Education': 'Inadequate_Education',\n",
    "    'Deforestation': 'Deforestation'\n",
    "})\n",
    "df['Interaction'] = df['Fuelwood_Collection'] * df['Inadequate_Education']\n",
    "\n",
    "model = smf.logit(\"Deforestation ~ Fuelwood_Collection + Inadequate_Education + Interaction\", data=df).fit()\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "# Creating a new DataFrame for prediction\n",
    "plot_data = pd.DataFrame({\n",
    "    'Fuelwood_Collection': np.tile(np.linspace(0, 1, 100), 2),\n",
    "    'Inadequate_Education': np.repeat([0, 1], 100)\n",
    "})\n",
    "plot_data['Interaction'] = plot_data['Fuelwood_Collection'] * plot_data['Inadequate_Education']\n",
    "plot_data['predicted_prob'] = model.predict(plot_data)\n",
    "\n",
    "# Plotting the moderation analysis\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.lineplot(\n",
    "    x='Fuelwood_Collection',\n",
    "    y='predicted_prob',\n",
    "    hue='Inadequate_Education',\n",
    "    palette='Set1',\n",
    "    data=plot_data\n",
    ")\n",
    "plt.title('Moderation Effect of Education on Fuelwood Collection and Deforestation')\n",
    "plt.xlabel('Fuelwood Collection (0=No, 1=Yes)')\n",
    "plt.ylabel('Predicted Probability of Deforestation')\n",
    "plt.legend(title='Inadequate Education')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"moderation_plot.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fdf2c7-00cf-41cb-b64b-5da272658eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating heat maps of land distribution across the respondents \n",
    "# Selecting the land use columns\n",
    "land_cols = ['Agriculture', 'Forest', 'Rangeland', 'Barren land']\n",
    "land_data = df[land_cols]\n",
    "\n",
    "# Creating the correlation matrix\n",
    "corr_matrix = land_data.corr()\n",
    "\n",
    "# Rows are respondents and columns are land use types\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(land_data, cmap='viridis', cbar=True, xticklabels=True, yticklabels=False)\n",
    "plt.title('Land Use Distribution Across Respondents')\n",
    "plt.xlabel('Land Use Type')\n",
    "plt.ylabel('Respondents')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"land_use_distribution_heatmap.png\", dpi=500)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3f4edc-33a0-438e-b62b-a1d666b68e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating heat maps of land use types across the respondents \n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='YlGnBu', linewidths=0.5)\n",
    "plt.title('Correlation Heatmap of Land Use Types')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"land_use_correlation_heatmap.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d54b9d2-d316-4746-adb1-1995048b1d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating heat maps of key deforestation drivers \n",
    "numeric_cols = ['Population Growth', 'Livelihood activities','Forest Fire',\t'Fuelwood Collection', 'Inadequate Education', 'Poor Forest Management',\n",
    "        'Illegal Logging',\t'Distance from Forest']\n",
    "\n",
    "# Computing the correlation\n",
    "corr_matrix = df[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", square=True,\n",
    "            cbar_kws={'shrink': 0.8}, annot_kws={\"size\": 10})\n",
    "\n",
    "plt.title(\"Correlation Heatmap of Key Deforestation Predictors\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Saving image (300 DPI)\n",
    "plt.savefig(\"figure3_correlation_heatmap.png\", dpi=500)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
